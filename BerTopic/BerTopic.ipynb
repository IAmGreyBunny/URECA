{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0141ee-5d71-4b76-b6ed-e9dd004ee78f",
   "metadata": {},
   "source": [
    "# BerTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e2519b-9b78-4f2f-8b44-4e122454a76d",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f390a36-418b-46d1-8bfa-4222f6d20a88",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b5f133-e723-4eb5-bfb9-65e6e09b76ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158ea9b5-dd74-4db6-a1ee-4979a3ad55e1",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4906a23-e197-4567-9212-87e044e93a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = \"models\"\n",
    "DATASET_FOLDER = \"data\"\n",
    "MODEL_TRAINING_LOG = \"training_log.csv\"\n",
    "RESULT_FILE = \"result.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8814009a-7594-4d5f-ae04-e4716652cd4d",
   "metadata": {},
   "source": [
    "### Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a45b26b6-242e-4a7c-a2d4-5a8567672ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d8aaf-3451-408d-95ce-73b74f309146",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ec847-26c1-452f-83b7-e8e7e26373e2",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f39fe2-df09-4574-b96b-3faec65295d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\URECA\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c0269c8-0ae0-4e07-8469-f6874552532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"SetFit/20_newsgroups\")\n",
    "random.seed(42)\n",
    "text_label = list(zip(dataset[\"train\"][\"text\"], dataset[\"train\"][\"label_text\"]))\n",
    "sampled_text_label = random.sample(text_label, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b4473-3672-4732-9298-0ab83a5f262a",
   "metadata": {},
   "source": [
    "### Clean Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12bc7720-e7f8-4749-837a-fc8eded30b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_for_embedding(text, max_sentences=5):\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if not line.strip().startswith(\">\")]\n",
    "    lines = [line for line in lines if not re.match(r\"^\\s*(from|subject|organization|lines|writes|article)\\s*:\", line, re.IGNORECASE)]\n",
    "    text = \" \".join(lines)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"[!?]{3,}\", \"\", text)\n",
    "    sentence_split = re.split(r'(?<=[.!?]) +', text)\n",
    "    sentence_split = [\n",
    "        s for s in sentence_split\n",
    "        if len(s.strip()) > 15 and not s.strip().isupper()\n",
    "      ]\n",
    "    return \" \".join(sentence_split[:max_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d4dfa8-e6f8-4b7d-bac8-5275fc4ba388",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_clean = [clean_for_embedding(text) for text,_ in sampled_text_label]\n",
    "labels = [label for _, label in sampled_text_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075daa7a-337d-45bc-9a5b-5f6247de0ba7",
   "metadata": {},
   "source": [
    "## 3. BerTopic Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53c0e39-9fd2-4331-8962-9bf79a481fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "import torch\n",
    "\n",
    "def train_bertopic(embedding_model,n_neighbors,n_components,min_cluster_size):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model_name = f\"{embedding_model}_{n_neighbors}_{n_components}_{min_cluster_size}\"\n",
    "\n",
    "    # Step 1 - Extract embeddings\n",
    "    print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "    embedding_model = SentenceTransformer(embedding_model,device)\n",
    "    \n",
    "    # Step 2 - Reduce dimensionality\n",
    "    umap_model = UMAP(n_neighbors=n_neighbors, n_components=n_components, min_dist=0.0, metric='cosine', random_state=42)\n",
    "    \n",
    "    # Step 3 - Cluster reduced embeddings\n",
    "    hdbscan_model = HDBSCAN(min_cluster_size=min_cluster_size, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "    \n",
    "    # Step 4 - Tokenize topics\n",
    "    vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "    \n",
    "    # Step 5 - Create topic representation\n",
    "    ctfidf_model = ClassTfidfTransformer()\n",
    "    \n",
    "    # Step 6 - (Optional) Fine-tune topic representations with\n",
    "    # a `bertopic.representation` model\n",
    "    representation_model = KeyBERTInspired()\n",
    "    \n",
    "    # All steps together\n",
    "    topic_model = BERTopic(\n",
    "        embedding_model=embedding_model, # Step 1 - Extract embeddings\n",
    "        umap_model=umap_model, # Step 2 - Reduce dimensionality\n",
    "        hdbscan_model=hdbscan_model, # Step 3 - Cluster reduced embeddings\n",
    "        vectorizer_model=vectorizer_model, # Step 4 - Tokenize topics\n",
    "        ctfidf_model=ctfidf_model, # Step 5 - Extract topic words\n",
    "        representation_model=representation_model # Step 6 - (Optional) Fine-tune topic representations\n",
    "    )\n",
    "    topics, probs = topic_model.fit_transform(texts_clean)\n",
    "    \n",
    "    topic_model.save(f\"{MODEL_FOLDER}/{model_name}\", serialization=\"pytorch\")\n",
    "\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fc535-babf-4f49-8179-4024fd150e2f",
   "metadata": {},
   "source": [
    "## 4. Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03083b60-6f21-4c58-890a-b3294aeeeb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models = pd.DataFrame(columns=[\"model_name\",\"train_time\"])\n",
    "\n",
    "# Create Log file if it doesn't exist\n",
    "if not os.path.exists(MODEL_TRAINING_LOG):\n",
    "    trained_models = pd.DataFrame(columns=[\"model_name\",\"train_time\"])\n",
    "    trained_models.to_csv(MODEL_TRAINING_LOG, index=False)\n",
    "else:\n",
    "    trained_models = pd.read_csv(MODEL_TRAINING_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddb93757-cc6e-438a-8174-7b94441b3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values to test for\n",
    "embedding_models = [\"all-mpnet-base-v2\",\"all-MiniLM-L6-v2\"]\n",
    "n_neighbors_range = [x for x in range(5,21)]\n",
    "n_components_range = [x for x in range(5,21)]\n",
    "min_cluster_size_range = [x for x in range(5,26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f92a7c2-4e2b-48e9-8ac6-53d8f7d22d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-mpnet-base-v2_5_5_5 had already been trained\n",
      "all-mpnet-base-v2_5_5_6 had already been trained\n",
      "all-mpnet-base-v2_5_5_7 had already been trained\n",
      "all-mpnet-base-v2_5_5_8 had already been trained\n",
      "all-mpnet-base-v2_5_5_9 had already been trained\n",
      "all-mpnet-base-v2_5_5_10 had already been trained\n",
      "all-mpnet-base-v2_5_5_11 had already been trained\n",
      "all-mpnet-base-v2_5_5_12 had already been trained\n",
      "all-mpnet-base-v2_5_5_13 had already been trained\n",
      "all-mpnet-base-v2_5_5_14 had already been trained\n",
      "all-mpnet-base-v2_5_5_15 had already been trained\n",
      "all-mpnet-base-v2_5_5_16 had already been trained\n",
      "all-mpnet-base-v2_5_5_17 had already been trained\n",
      "all-mpnet-base-v2_5_5_18 had already been trained\n",
      "all-mpnet-base-v2_5_5_19 had already been trained\n",
      "all-mpnet-base-v2_5_5_20 had already been trained\n",
      "all-mpnet-base-v2_5_5_21 had already been trained\n",
      "all-mpnet-base-v2_5_5_22 had already been trained\n",
      "all-mpnet-base-v2_5_5_23 had already been trained\n",
      "all-mpnet-base-v2_5_5_24 had already been trained\n",
      "all-mpnet-base-v2_5_5_25 had already been trained\n",
      "all-mpnet-base-v2_5_6_5 had already been trained\n",
      "all-mpnet-base-v2_5_6_6 had already been trained\n",
      "all-mpnet-base-v2_5_6_7 had already been trained\n",
      "all-mpnet-base-v2_5_6_8 had already been trained\n",
      "all-mpnet-base-v2_5_6_9 had already been trained\n",
      "all-mpnet-base-v2_5_6_10 had already been trained\n",
      "all-mpnet-base-v2_5_6_11 had already been trained\n",
      "all-mpnet-base-v2_5_6_12 had already been trained\n",
      "all-mpnet-base-v2_5_6_13 had already been trained\n",
      "all-mpnet-base-v2_5_6_14 had already been trained\n",
      "all-mpnet-base-v2_5_6_15 had already been trained\n",
      "all-mpnet-base-v2_5_6_16 had already been trained\n",
      "all-mpnet-base-v2_5_6_17 had already been trained\n",
      "all-mpnet-base-v2_5_6_18 had already been trained\n",
      "all-mpnet-base-v2_5_6_19 had already been trained\n",
      "all-mpnet-base-v2_5_6_20 had already been trained\n",
      "all-mpnet-base-v2_5_6_21 had already been trained\n",
      "all-mpnet-base-v2_5_6_22 had already been trained\n",
      "all-mpnet-base-v2_5_6_23 had already been trained\n",
      "all-mpnet-base-v2_5_6_24 had already been trained\n",
      "all-mpnet-base-v2_5_6_25 had already been trained\n",
      "all-mpnet-base-v2_5_7_5 had already been trained\n",
      "all-mpnet-base-v2_5_7_6 had already been trained\n",
      "all-mpnet-base-v2_5_7_7 had already been trained\n",
      "all-mpnet-base-v2_5_7_8 had already been trained\n",
      "all-mpnet-base-v2_5_7_9 had already been trained\n",
      "all-mpnet-base-v2_5_7_10 had already been trained\n",
      "all-mpnet-base-v2_5_7_11 had already been trained\n",
      "all-mpnet-base-v2_5_7_12 had already been trained\n",
      "all-mpnet-base-v2_5_7_13 had already been trained\n",
      "all-mpnet-base-v2_5_7_14 had already been trained\n",
      "all-mpnet-base-v2_5_7_15 had already been trained\n",
      "all-mpnet-base-v2_5_7_16 had already been trained\n",
      "all-mpnet-base-v2_5_7_17 had already been trained\n",
      "all-mpnet-base-v2_5_7_18 had already been trained\n",
      "all-mpnet-base-v2_5_7_19 had already been trained\n",
      "all-mpnet-base-v2_5_7_20 had already been trained\n",
      "all-mpnet-base-v2_5_7_21 had already been trained\n",
      "all-mpnet-base-v2_5_7_22 had already been trained\n",
      "all-mpnet-base-v2_5_7_23 had already been trained\n",
      "all-mpnet-base-v2_5_7_24 had already been trained\n",
      "all-mpnet-base-v2_5_7_25 had already been trained\n",
      "all-mpnet-base-v2_5_8_5 had already been trained\n",
      "all-mpnet-base-v2_5_8_6 had already been trained\n",
      "all-mpnet-base-v2_5_8_7 had already been trained\n",
      "all-mpnet-base-v2_5_8_8 had already been trained\n",
      "all-mpnet-base-v2_5_8_9 had already been trained\n",
      "all-mpnet-base-v2_5_8_10 had already been trained\n",
      "all-mpnet-base-v2_5_8_11 had already been trained\n",
      "all-mpnet-base-v2_5_8_12 had already been trained\n",
      "all-mpnet-base-v2_5_8_13 had already been trained\n",
      "all-mpnet-base-v2_5_8_14 had already been trained\n",
      "all-mpnet-base-v2_5_8_15 had already been trained\n",
      "all-mpnet-base-v2_5_8_16 had already been trained\n",
      "all-mpnet-base-v2_5_8_17 had already been trained\n",
      "all-mpnet-base-v2_5_8_18 had already been trained\n",
      "all-mpnet-base-v2_5_8_19 had already been trained\n",
      "all-mpnet-base-v2_5_8_20 had already been trained\n",
      "all-mpnet-base-v2_5_8_21 had already been trained\n",
      "all-mpnet-base-v2_5_8_22 had already been trained\n",
      "all-mpnet-base-v2_5_8_23 had already been trained\n",
      "all-mpnet-base-v2_5_8_24 had already been trained\n",
      "all-mpnet-base-v2_5_8_25 had already been trained\n",
      "all-mpnet-base-v2_5_9_5 had already been trained\n",
      "all-mpnet-base-v2_5_9_6 had already been trained\n",
      "all-mpnet-base-v2_5_9_7 had already been trained\n",
      "all-mpnet-base-v2_5_9_8 had already been trained\n",
      "all-mpnet-base-v2_5_9_9 had already been trained\n",
      "all-mpnet-base-v2_5_9_10 had already been trained\n",
      "all-mpnet-base-v2_5_9_11 had already been trained\n",
      "all-mpnet-base-v2_5_9_12 had already been trained\n",
      "all-mpnet-base-v2_5_9_13 had already been trained\n",
      "all-mpnet-base-v2_5_9_14 had already been trained\n",
      "all-mpnet-base-v2_5_9_15 had already been trained\n",
      "all-mpnet-base-v2_5_9_16 had already been trained\n",
      "all-mpnet-base-v2_5_9_17 had already been trained\n",
      "all-mpnet-base-v2_5_9_18 had already been trained\n",
      "all-mpnet-base-v2_5_9_19 had already been trained\n",
      "all-mpnet-base-v2_5_9_20 had already been trained\n",
      "all-mpnet-base-v2_5_9_21 had already been trained\n",
      "all-mpnet-base-v2_5_9_22 had already been trained\n",
      "all-mpnet-base-v2_5_9_23 had already been trained\n",
      "all-mpnet-base-v2_5_9_24 had already been trained\n",
      "all-mpnet-base-v2_5_9_25 had already been trained\n",
      "all-mpnet-base-v2_5_10_5 had already been trained\n",
      "all-mpnet-base-v2_5_10_6 had already been trained\n",
      "all-mpnet-base-v2_5_10_7 had already been trained\n",
      "all-mpnet-base-v2_5_10_8 had already been trained\n",
      "all-mpnet-base-v2_5_10_9 had already been trained\n",
      "all-mpnet-base-v2_5_10_10 had already been trained\n",
      "all-mpnet-base-v2_5_10_11 had already been trained\n",
      "all-mpnet-base-v2_5_10_12 had already been trained\n",
      "all-mpnet-base-v2_5_10_13 had already been trained\n",
      "all-mpnet-base-v2_5_10_14 had already been trained\n",
      "all-mpnet-base-v2_5_10_15 had already been trained\n",
      "all-mpnet-base-v2_5_10_16 had already been trained\n",
      "all-mpnet-base-v2_5_10_17 had already been trained\n",
      "all-mpnet-base-v2_5_10_18 had already been trained\n",
      "all-mpnet-base-v2_5_10_19 had already been trained\n",
      "all-mpnet-base-v2_5_10_20 had already been trained\n",
      "all-mpnet-base-v2_5_10_21 had already been trained\n",
      "all-mpnet-base-v2_5_10_22 had already been trained\n",
      "all-mpnet-base-v2_5_10_23 had already been trained\n",
      "all-mpnet-base-v2_5_10_24 had already been trained\n",
      "all-mpnet-base-v2_5_10_25 had already been trained\n",
      "all-mpnet-base-v2_5_11_5 had already been trained\n",
      "all-mpnet-base-v2_5_11_6 had already been trained\n",
      "all-mpnet-base-v2_5_11_7 had already been trained\n",
      "all-mpnet-base-v2_5_11_8 had already been trained\n",
      "all-mpnet-base-v2_5_11_9 had already been trained\n",
      "all-mpnet-base-v2_5_11_10 had already been trained\n",
      "all-mpnet-base-v2_5_11_11 had already been trained\n",
      "all-mpnet-base-v2_5_11_12 had already been trained\n",
      "all-mpnet-base-v2_5_11_13 had already been trained\n",
      "all-mpnet-base-v2_5_11_14 had already been trained\n",
      "all-mpnet-base-v2_5_11_15 had already been trained\n",
      "all-mpnet-base-v2_5_11_16 had already been trained\n",
      "all-mpnet-base-v2_5_11_17 had already been trained\n",
      "all-mpnet-base-v2_5_11_18 had already been trained\n",
      "all-mpnet-base-v2_5_11_19 had already been trained\n",
      "all-mpnet-base-v2_5_11_20 had already been trained\n",
      "all-mpnet-base-v2_5_11_21 had already been trained\n",
      "all-mpnet-base-v2_5_11_22 had already been trained\n",
      "all-mpnet-base-v2_5_11_23 had already been trained\n",
      "all-mpnet-base-v2_5_11_24 had already been trained\n",
      "all-mpnet-base-v2_5_11_25 had already been trained\n",
      "all-mpnet-base-v2_5_12_5 had already been trained\n",
      "all-mpnet-base-v2_5_12_6 had already been trained\n",
      "all-mpnet-base-v2_5_12_7 had already been trained\n",
      "all-mpnet-base-v2_5_12_8 had already been trained\n",
      "all-mpnet-base-v2_5_12_9 had already been trained\n",
      "all-mpnet-base-v2_5_12_10 had already been trained\n",
      "all-mpnet-base-v2_5_12_11 had already been trained\n",
      "all-mpnet-base-v2_5_12_12 had already been trained\n",
      "all-mpnet-base-v2_5_12_13 had already been trained\n",
      "all-mpnet-base-v2_5_12_14 had already been trained\n",
      "all-mpnet-base-v2_5_12_15 had already been trained\n",
      "all-mpnet-base-v2_5_12_16 had already been trained\n",
      "all-mpnet-base-v2_5_12_17 had already been trained\n",
      "all-mpnet-base-v2_5_12_18 had already been trained\n",
      "all-mpnet-base-v2_5_12_19 had already been trained\n",
      "all-mpnet-base-v2_5_12_20 had already been trained\n",
      "all-mpnet-base-v2_5_12_21 had already been trained\n",
      "all-mpnet-base-v2_5_12_22 had already been trained\n",
      "all-mpnet-base-v2_5_12_23 had already been trained\n",
      "all-mpnet-base-v2_5_12_24 had already been trained\n",
      "all-mpnet-base-v2_5_12_25 had already been trained\n",
      "all-mpnet-base-v2_5_13_5 had already been trained\n",
      "all-mpnet-base-v2_5_13_6 had already been trained\n",
      "all-mpnet-base-v2_5_13_7 had already been trained\n",
      "all-mpnet-base-v2_5_13_8 had already been trained\n",
      "all-mpnet-base-v2_5_13_9 had already been trained\n",
      "all-mpnet-base-v2_5_13_10 had already been trained\n",
      "all-mpnet-base-v2_5_13_11 had already been trained\n",
      "all-mpnet-base-v2_5_13_12 had already been trained\n",
      "all-mpnet-base-v2_5_13_13 had already been trained\n",
      "all-mpnet-base-v2_5_13_14 had already been trained\n",
      "all-mpnet-base-v2_5_13_15 had already been trained\n",
      "all-mpnet-base-v2_5_13_16 had already been trained\n",
      "all-mpnet-base-v2_5_13_17 had already been trained\n",
      "all-mpnet-base-v2_5_13_18 had already been trained\n",
      "all-mpnet-base-v2_5_13_19 had already been trained\n",
      "all-mpnet-base-v2_5_13_20 had already been trained\n",
      "all-mpnet-base-v2_5_13_21 had already been trained\n",
      "all-mpnet-base-v2_5_13_22 had already been trained\n",
      "all-mpnet-base-v2_5_13_23 had already been trained\n",
      "all-mpnet-base-v2_5_13_24 had already been trained\n",
      "all-mpnet-base-v2_5_13_25 had already been trained\n",
      "all-mpnet-base-v2_5_14_5 had already been trained\n",
      "all-mpnet-base-v2_5_14_6 had already been trained\n",
      "all-mpnet-base-v2_5_14_7 had already been trained\n",
      "all-mpnet-base-v2_5_14_8 had already been trained\n",
      "all-mpnet-base-v2_5_14_9 had already been trained\n",
      "all-mpnet-base-v2_5_14_10 had already been trained\n",
      "all-mpnet-base-v2_5_14_11 had already been trained\n",
      "all-mpnet-base-v2_5_14_12 had already been trained\n",
      "all-mpnet-base-v2_5_14_13 had already been trained\n",
      "all-mpnet-base-v2_5_14_14 had already been trained\n",
      "all-mpnet-base-v2_5_14_15 had already been trained\n",
      "all-mpnet-base-v2_5_14_16 had already been trained\n",
      "all-mpnet-base-v2_5_14_17 had already been trained\n",
      "all-mpnet-base-v2_5_14_18 had already been trained\n",
      "all-mpnet-base-v2_5_14_19 had already been trained\n",
      "all-mpnet-base-v2_5_14_20 had already been trained\n",
      "all-mpnet-base-v2_5_14_21 had already been trained\n",
      "all-mpnet-base-v2_5_14_22 had already been trained\n",
      "all-mpnet-base-v2_5_14_23 had already been trained\n",
      "all-mpnet-base-v2_5_14_24 had already been trained\n",
      "all-mpnet-base-v2_5_14_25 had already been trained\n",
      "all-mpnet-base-v2_5_15_5 had already been trained\n",
      "all-mpnet-base-v2_5_15_6 had already been trained\n",
      "all-mpnet-base-v2_5_15_7 had already been trained\n",
      "all-mpnet-base-v2_5_15_8 had already been trained\n",
      "all-mpnet-base-v2_5_15_9 had already been trained\n",
      "all-mpnet-base-v2_5_15_10 had already been trained\n",
      "all-mpnet-base-v2_5_15_11 had already been trained\n",
      "all-mpnet-base-v2_5_15_12 had already been trained\n",
      "all-mpnet-base-v2_5_15_13 had already been trained\n",
      "all-mpnet-base-v2_5_15_14 had already been trained\n",
      "all-mpnet-base-v2_5_15_15 had already been trained\n",
      "all-mpnet-base-v2_5_15_16 had already been trained\n",
      "all-mpnet-base-v2_5_15_17 had already been trained\n",
      "all-mpnet-base-v2_5_15_18 had already been trained\n",
      "all-mpnet-base-v2_5_15_19 had already been trained\n",
      "all-mpnet-base-v2_5_15_20 had already been trained\n",
      "all-mpnet-base-v2_5_15_21 had already been trained\n",
      "all-mpnet-base-v2_5_15_22 had already been trained\n",
      "all-mpnet-base-v2_5_15_23 had already been trained\n",
      "CUDA Available: True\n",
      "Trained all-mpnet-base-v2_5_15_24 in 38.70871305465698\n",
      "CUDA Available: True\n",
      "Trained all-mpnet-base-v2_5_15_25 in 38.093668699264526\n",
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "for embedding_model in embedding_models:\n",
    "    for n_neighbors in n_neighbors_range:\n",
    "        for n_components in n_components_range:\n",
    "            for min_cluster_size in min_cluster_size_range:\n",
    "                model_name = f\"{embedding_model}_{n_neighbors}_{n_components}_{min_cluster_size}\"\n",
    "                if model_name in trained_models[\"model_name\"].values:\n",
    "                    print(f\"{model_name} had already been trained\")\n",
    "                    continue\n",
    "                else:\n",
    "                    start_time = time.time()\n",
    "                    model_name = train_bertopic(embedding_model,n_neighbors,n_components,min_cluster_size)\n",
    "                    end_time = time.time()\n",
    "                    train_time = end_time-start_time\n",
    "                    \n",
    "                    # Write to training log\n",
    "                    new_row = pd.DataFrame({\"model_name\": [model_name],\"train_time\":[train_time]})\n",
    "                    trained_models = pd.concat([trained_models, new_row], ignore_index=True)\n",
    "                    trained_models.to_csv(MODEL_TRAINING_LOG, index=False)\n",
    "                    \n",
    "                    # Print Status\n",
    "                    print(f\"Trained {model_name} in {train_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4125b8-9e2d-4bd9-a3d8-c3d1ca8d7c06",
   "metadata": {},
   "source": [
    "## 5. Result (Best Model) - WIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ee959-9d1c-423b-9c3d-5ce4a70de563",
   "metadata": {},
   "source": [
    "### Topic Info (Monogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e19e6-7e0c-4104-adb3-d79e6b736c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "monogram_topic_model = BERTopic.load(\"topic_model\",embedding_model=embedding_model)\n",
    "monogram_topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc36926-f73b-4e6d-94f2-cb9f434236e1",
   "metadata": {},
   "source": [
    "### Topic Info (Multigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663dcec9-f8f7-492d-9535-37e9c202853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multigram_topic_model = BERTopic.load(\"topic_model\",embedding_model=embedding_model)\n",
    "multigram_topic_model.update_topics(texts_clean, vectorizer_model=CountVectorizer(stop_words=\"english\", ngram_range=(2,3)))\n",
    "multigram_topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3afba-bedb-4e22-a531-148e71e23202",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a63bc3-db86-4f32-8ee4-2de13c4c4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Tokenize Document\n",
    "tokenized_texts = [[str(token) for token in doc.split() if token.strip() != ''] for doc in texts_clean]\n",
    "\n",
    "# Create Dictionary\n",
    "dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "# Extract Topics\n",
    "# Filter topic words to exist in the dictionary\n",
    "topics = [\n",
    "    [str(word) for word, _ in words_probs if str(word) in dictionary.token2id]\n",
    "    for topic_id, words_probs in monogram_topic_model.get_topics().items()\n",
    "    if topic_id != -1\n",
    "]\n",
    "\n",
    "# Remove empty topics (just in case)\n",
    "topics = [t for t in topics if len(t) > 0]\n",
    "\n",
    "# Compute Coherence\n",
    "coherence_model = CoherenceModel(\n",
    "    topics=topics,\n",
    "    texts=tokenized_texts,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "\n",
    "monogram_coherence = coherence_model.get_coherence()\n",
    "print(\"Monogram C_v Coherence:\", monogram_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7e1f9f-b717-42ef-8bf7-c6835d9beebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [doc.split() for doc in texts_clean]\n",
    "dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "# Topics have to be split into singular words\n",
    "topics = [\n",
    "    sum([word.split() for word, _ in multigram_topic_model.get_topic(topic)], [])\n",
    "    for topic in multigram_topic_model.get_topics().keys()\n",
    "    if topic != -1\n",
    "]\n",
    "\n",
    "# Remove empty topics (just in case)\n",
    "topics = [t for t in topics if len(t) > 0]\n",
    "\n",
    "coherence_model = CoherenceModel(\n",
    "    topics=topics,\n",
    "    texts=tokenized_texts,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "\n",
    "multigram_coherence = coherence_model.get_coherence()\n",
    "print(\"Multigram C_v Coherence:\", multigram_coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8d8dd-4466-42b9-bc84-b0d62d2bec92",
   "metadata": {},
   "source": [
    "## 6. Using LLM to Improve Representation (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ab163-622c-44e3-94df-530c09acc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from bertopic.representation import OpenAI\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "topic_model.update_topics(texts_clean, representation_model=OpenAI(client, model=\"gpt-4o-mini\", delay_in_seconds=3))\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0344cd0-ca4e-41cd-825d-c31ac30c24c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
