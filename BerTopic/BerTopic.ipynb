{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0141ee-5d71-4b76-b6ed-e9dd004ee78f",
   "metadata": {},
   "source": [
    "# BerTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f390a36-418b-46d1-8bfa-4222f6d20a88",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b5f133-e723-4eb5-bfb9-65e6e09b76ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d8aaf-3451-408d-95ce-73b74f309146",
   "metadata": {},
   "source": [
    "## Loading Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2f39fe2-df09-4574-b96b-3faec65295d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\URECA\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0269c8-0ae0-4e07-8469-f6874552532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"SetFit/20_newsgroups\")\n",
    "random.seed(42)\n",
    "text_label = list(zip(dataset[\"train\"][\"text\"], dataset[\"train\"][\"label_text\"]))\n",
    "sampled_text_label = random.sample(text_label, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43b4473-3672-4732-9298-0ab83a5f262a",
   "metadata": {},
   "source": [
    "## Clean Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bc7720-e7f8-4749-837a-fc8eded30b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_for_embedding(text, max_sentences=5):\n",
    "    lines = text.split(\"\\n\")\n",
    "    lines = [line for line in lines if not line.strip().startswith(\">\")]\n",
    "    lines = [line for line in lines if not re.match(r\"^\\s*(from|subject|organization|lines|writes|article)\\s*:\", line, re.IGNORECASE)]\n",
    "    text = \" \".join(lines)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"[!?]{3,}\", \"\", text)\n",
    "    sentence_split = re.split(r'(?<=[.!?]) +', text)\n",
    "    sentence_split = [\n",
    "        s for s in sentence_split\n",
    "        if len(s.strip()) > 15 and not s.strip().isupper()\n",
    "      ]\n",
    "    return \" \".join(sentence_split[:max_sentences])\n",
    "texts_clean = [clean_for_embedding(text) for text,_ in sampled_text_label]\n",
    "labels = [label for _, label in sampled_text_label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075daa7a-337d-45bc-9a5b-5f6247de0ba7",
   "metadata": {},
   "source": [
    "## BerTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53c0e39-9fd2-4331-8962-9bf79a481fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "#embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\",device)\n",
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\",device)\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# Step 6 - (Optional) Fine-tune topic representations with\n",
    "# a `bertopic.representation` model\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "# All steps together\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model, # Step 1 - Extract embeddings\n",
    "    umap_model=umap_model, # Step 2 - Reduce dimensionality\n",
    "    hdbscan_model=hdbscan_model, # Step 3 - Cluster reduced embeddings\n",
    "    vectorizer_model=vectorizer_model, # Step 4 - Tokenize topics\n",
    "    ctfidf_model=ctfidf_model, # Step 5 - Extract topic words\n",
    "    representation_model=representation_model # Step 6 - (Optional) Fine-tune topic representations\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(texts_clean)\n",
    "\n",
    "topic_model.save(\"topic_model\", serialization=\"pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4125b8-9e2d-4bd9-a3d8-c3d1ca8d7c06",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ee959-9d1c-423b-9c3d-5ce4a70de563",
   "metadata": {},
   "source": [
    "## Topic Info (Monogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079e19e6-7e0c-4104-adb3-d79e6b736c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 21:15:13,786 - BERTopic - WARNING: You are loading a BERTopic model without explicitly defining an embedding model. If you want to also load in an embedding model, make sure to use `BERTopic.load(my_model, embedding_model=my_embedding_model)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3038</td>\n",
       "      <td>-1_graphics_heard_version_display</td>\n",
       "      <td>[graphics, heard, version, display, looking, a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>992</td>\n",
       "      <td>0_toyota_ford_didn_don</td>\n",
       "      <td>[toyota, ford, didn, don, did, think, good, do...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>412</td>\n",
       "      <td>1_announcement_possible_patent_new</td>\n",
       "      <td>[announcement, possible, patent, new, make, us...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>2_det_82_81_60</td>\n",
       "      <td>[det, 82, 81, 60, 73, 58, nhl, van, 78, 72]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>367</td>\n",
       "      <td>3_offensive_fan_east_don</td>\n",
       "      <td>[offensive, fan, east, don, hit, houston, defe...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>70_premises_discussion_argue_evolutionism</td>\n",
       "      <td>[premises, discussion, argue, evolutionism, th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>71</td>\n",
       "      <td>16</td>\n",
       "      <td>71_operators_results_announcing_previdi</td>\n",
       "      <td>[operators, results, announcing, previdi, aren...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>72_motif_odd_translations_translation</td>\n",
       "      <td>[motif, odd, translations, translation, insert...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>73</td>\n",
       "      <td>15</td>\n",
       "      <td>73_0f000_supposedly_0a000_yielded</td>\n",
       "      <td>[0f000, supposedly, 0a000, yielded, 0e000, res...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>74</td>\n",
       "      <td>15</td>\n",
       "      <td>74_city_inmates_values_hostage</td>\n",
       "      <td>[city, inmates, values, hostage, streets, huma...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                       Name  \\\n",
       "0      -1   3038          -1_graphics_heard_version_display   \n",
       "1       0    992                     0_toyota_ford_didn_don   \n",
       "2       1    412         1_announcement_possible_patent_new   \n",
       "3       2    394                             2_det_82_81_60   \n",
       "4       3    367                   3_offensive_fan_east_don   \n",
       "..    ...    ...                                        ...   \n",
       "71     70     17  70_premises_discussion_argue_evolutionism   \n",
       "72     71     16    71_operators_results_announcing_previdi   \n",
       "73     72     15      72_motif_odd_translations_translation   \n",
       "74     73     15          73_0f000_supposedly_0a000_yielded   \n",
       "75     74     15             74_city_inmates_values_hostage   \n",
       "\n",
       "                                       Representation  Representative_Docs  \n",
       "0   [graphics, heard, version, display, looking, a...                  NaN  \n",
       "1   [toyota, ford, didn, don, did, think, good, do...                  NaN  \n",
       "2   [announcement, possible, patent, new, make, us...                  NaN  \n",
       "3         [det, 82, 81, 60, 73, 58, nhl, van, 78, 72]                  NaN  \n",
       "4   [offensive, fan, east, don, hit, houston, defe...                  NaN  \n",
       "..                                                ...                  ...  \n",
       "71  [premises, discussion, argue, evolutionism, th...                  NaN  \n",
       "72  [operators, results, announcing, previdi, aren...                  NaN  \n",
       "73  [motif, odd, translations, translation, insert...                  NaN  \n",
       "74  [0f000, supposedly, 0a000, yielded, 0e000, res...                  NaN  \n",
       "75  [city, inmates, values, hostage, streets, huma...                  NaN  \n",
       "\n",
       "[76 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monogram_topic_model = BERTopic.load(\"topic_model\")\n",
    "monogram_topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc36926-f73b-4e6d-94f2-cb9f434236e1",
   "metadata": {},
   "source": [
    "## Topic Info (Multigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663dcec9-f8f7-492d-9535-37e9c202853f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 21:15:13,806 - BERTopic - WARNING: You are loading a BERTopic model without explicitly defining an embedding model. If you want to also load in an embedding model, make sure to use `BERTopic.load(my_model, embedding_model=my_embedding_model)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3038</td>\n",
       "      <td>-1_don know_does know_years ago_thanks advance</td>\n",
       "      <td>[don know, does know, years ago, thanks advanc...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>992</td>\n",
       "      <td>0_send requests_000 miles_don know_new car</td>\n",
       "      <td>[send requests, 000 miles, don know, new car, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>412</td>\n",
       "      <td>1_clipper chip_serial number_law enforcement_p...</td>\n",
       "      <td>[clipper chip, serial number, law enforcement,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>2_st john_cape breton_pts pt_maple leafs</td>\n",
       "      <td>[st john, cape breton, pts pt, maple leafs, 15...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>367</td>\n",
       "      <td>3_00 00_00 00 00_01 00_00 01</td>\n",
       "      <td>[00 00, 00 00 00, 01 00, 00 01, red sox, 00 00...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>70_assume god just_assume god_did create_just ...</td>\n",
       "      <td>[assume god just, assume god, did create, just...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>71</td>\n",
       "      <td>16</td>\n",
       "      <td>71_junk mail_improper etiquette_printing busin...</td>\n",
       "      <td>[junk mail, improper etiquette, printing busin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>72_menu accelerators_f1 key_arrow keys_string ...</td>\n",
       "      <td>[menu accelerators, f1 key, arrow keys, string...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>73</td>\n",
       "      <td>15</td>\n",
       "      <td>73_version winbench_stealth 24_revision board_...</td>\n",
       "      <td>[version winbench, stealth 24, revision board,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>74</td>\n",
       "      <td>15</td>\n",
       "      <td>74_inner city_minimum wage_african americans_j...</td>\n",
       "      <td>[inner city, minimum wage, african americans, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                               Name  \\\n",
       "0      -1   3038     -1_don know_does know_years ago_thanks advance   \n",
       "1       0    992         0_send requests_000 miles_don know_new car   \n",
       "2       1    412  1_clipper chip_serial number_law enforcement_p...   \n",
       "3       2    394           2_st john_cape breton_pts pt_maple leafs   \n",
       "4       3    367                       3_00 00_00 00 00_01 00_00 01   \n",
       "..    ...    ...                                                ...   \n",
       "71     70     17  70_assume god just_assume god_did create_just ...   \n",
       "72     71     16  71_junk mail_improper etiquette_printing busin...   \n",
       "73     72     15  72_menu accelerators_f1 key_arrow keys_string ...   \n",
       "74     73     15  73_version winbench_stealth 24_revision board_...   \n",
       "75     74     15  74_inner city_minimum wage_african americans_j...   \n",
       "\n",
       "                                       Representation  Representative_Docs  \n",
       "0   [don know, does know, years ago, thanks advanc...                  NaN  \n",
       "1   [send requests, 000 miles, don know, new car, ...                  NaN  \n",
       "2   [clipper chip, serial number, law enforcement,...                  NaN  \n",
       "3   [st john, cape breton, pts pt, maple leafs, 15...                  NaN  \n",
       "4   [00 00, 00 00 00, 01 00, 00 01, red sox, 00 00...                  NaN  \n",
       "..                                                ...                  ...  \n",
       "71  [assume god just, assume god, did create, just...                  NaN  \n",
       "72  [junk mail, improper etiquette, printing busin...                  NaN  \n",
       "73  [menu accelerators, f1 key, arrow keys, string...                  NaN  \n",
       "74  [version winbench, stealth 24, revision board,...                  NaN  \n",
       "75  [inner city, minimum wage, african americans, ...                  NaN  \n",
       "\n",
       "[76 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multigram_topic_model = BERTopic.load(\"topic_model\")\n",
    "multigram_topic_model.update_topics(texts_clean, vectorizer_model=CountVectorizer(stop_words=\"english\", ngram_range=(2,3)))\n",
    "multigram_topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3afba-bedb-4e22-a531-148e71e23202",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54a63bc3-db86-4f32-8ee4-2de13c4c4321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monogram C_v Coherence: 0.34327752059953076\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# Tokenize Document\n",
    "tokenized_texts = [[str(token) for token in doc.split() if token.strip() != ''] for doc in texts_clean]\n",
    "\n",
    "# Create Dictionary\n",
    "dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "# Extract Topics\n",
    "# Filter topic words to exist in the dictionary\n",
    "topics = [\n",
    "    [str(word) for word, _ in words_probs if str(word) in dictionary.token2id]\n",
    "    for topic_id, words_probs in monogram_topic_model.get_topics().items()\n",
    "    if topic_id != -1\n",
    "]\n",
    "\n",
    "# Remove empty topics (just in case)\n",
    "topics = [t for t in topics if len(t) > 0]\n",
    "\n",
    "# Compute Coherence\n",
    "coherence_model = CoherenceModel(\n",
    "    topics=topics,\n",
    "    texts=tokenized_texts,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "\n",
    "monogram_coherence = coherence_model.get_coherence()\n",
    "print(\"Monogram C_v Coherence:\", monogram_coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c7e1f9f-b717-42ef-8bf7-c6835d9beebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multigram C_v Coherence: 0.4047546849501282\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = [doc.split() for doc in texts_clean]\n",
    "dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "# Topics have to be split into singular words\n",
    "topics = [\n",
    "    sum([word.split() for word, _ in multigram_topic_model.get_topic(topic)], [])\n",
    "    for topic in multigram_topic_model.get_topics().keys()\n",
    "    if topic != -1\n",
    "]\n",
    "\n",
    "# Remove empty topics (just in case)\n",
    "topics = [t for t in topics if len(t) > 0]\n",
    "\n",
    "coherence_model = CoherenceModel(\n",
    "    topics=topics,\n",
    "    texts=tokenized_texts,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "\n",
    "multigram_coherence = coherence_model.get_coherence()\n",
    "print(\"Multigram C_v Coherence:\", multigram_coherence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b8d8dd-4466-42b9-bc84-b0d62d2bec92",
   "metadata": {},
   "source": [
    "## Using LLM to Improve Representation (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "636ab163-622c-44e3-94df-530c09acc824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3038</td>\n",
       "      <td>-1_Religion and navigation</td>\n",
       "      <td>[Religion and navigation]</td>\n",
       "      <td>[Title just 'bout says it all: Grasshopper Rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>992</td>\n",
       "      <td>0_Motorcycle purchasing advice</td>\n",
       "      <td>[Motorcycle purchasing advice]</td>\n",
       "      <td>[I'm new to motorcycles so no flames please. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>412</td>\n",
       "      <td>1_Clipper encryption system</td>\n",
       "      <td>[Clipper encryption system]</td>\n",
       "      <td>[One more time... If they released the algorit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>2_NHL Player Statistics</td>\n",
       "      <td>[NHL Player Statistics]</td>\n",
       "      <td>[Here is the price list for the week April 13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>367</td>\n",
       "      <td>3_MLB Standings Updates</td>\n",
       "      <td>[MLB Standings Updates]</td>\n",
       "      <td>[MLB Standings and Scores for Tuesday, April 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>70</td>\n",
       "      <td>17</td>\n",
       "      <td>70_Existence of the Universe</td>\n",
       "      <td>[Existence of the Universe]</td>\n",
       "      <td>[= = : [ The discussion begins: why does the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>71</td>\n",
       "      <td>16</td>\n",
       "      <td>71_Usenet Advertising Etiquette</td>\n",
       "      <td>[Usenet Advertising Etiquette]</td>\n",
       "      <td>[\"Jack Previdi\" &lt;p00020@psilink.com&gt; writes, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>72_Keyboard Event Handling</td>\n",
       "      <td>[Keyboard Event Handling]</td>\n",
       "      <td>[Unfortunately, the key event handling is pret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>73</td>\n",
       "      <td>15</td>\n",
       "      <td>73_Video Card Benchmarks</td>\n",
       "      <td>[Video Card Benchmarks]</td>\n",
       "      <td>[On ftp.cica.indiana.edu in pub/pc/win3/misc/w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>74</td>\n",
       "      <td>15</td>\n",
       "      <td>74_Socioeconomic Factors and Crime</td>\n",
       "      <td>[Socioeconomic Factors and Crime]</td>\n",
       "      <td>[Article in this morning's Houston Post....\"ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                Name  \\\n",
       "0      -1   3038          -1_Religion and navigation   \n",
       "1       0    992      0_Motorcycle purchasing advice   \n",
       "2       1    412         1_Clipper encryption system   \n",
       "3       2    394             2_NHL Player Statistics   \n",
       "4       3    367             3_MLB Standings Updates   \n",
       "..    ...    ...                                 ...   \n",
       "71     70     17        70_Existence of the Universe   \n",
       "72     71     16     71_Usenet Advertising Etiquette   \n",
       "73     72     15          72_Keyboard Event Handling   \n",
       "74     73     15            73_Video Card Benchmarks   \n",
       "75     74     15  74_Socioeconomic Factors and Crime   \n",
       "\n",
       "                       Representation  \\\n",
       "0           [Religion and navigation]   \n",
       "1      [Motorcycle purchasing advice]   \n",
       "2         [Clipper encryption system]   \n",
       "3             [NHL Player Statistics]   \n",
       "4             [MLB Standings Updates]   \n",
       "..                                ...   \n",
       "71        [Existence of the Universe]   \n",
       "72     [Usenet Advertising Etiquette]   \n",
       "73          [Keyboard Event Handling]   \n",
       "74            [Video Card Benchmarks]   \n",
       "75  [Socioeconomic Factors and Crime]   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [Title just 'bout says it all: Grasshopper Rem...  \n",
       "1   [I'm new to motorcycles so no flames please. I...  \n",
       "2   [One more time... If they released the algorit...  \n",
       "3   [Here is the price list for the week April 13 ...  \n",
       "4   [MLB Standings and Scores for Tuesday, April 6...  \n",
       "..                                                ...  \n",
       "71  [= = : [ The discussion begins: why does the u...  \n",
       "72  [\"Jack Previdi\" <p00020@psilink.com> writes, i...  \n",
       "73  [Unfortunately, the key event handling is pret...  \n",
       "74  [On ftp.cica.indiana.edu in pub/pc/win3/misc/w...  \n",
       "75  [Article in this morning's Houston Post....\"ne...  \n",
       "\n",
       "[76 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from bertopic.representation import OpenAI\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "topic_model.update_topics(texts_clean, representation_model=OpenAI(client, model=\"gpt-4o-mini\", delay_in_seconds=3))\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0344cd0-ca4e-41cd-825d-c31ac30c24c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
